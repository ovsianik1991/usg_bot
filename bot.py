import os
import asyncio
import requests
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command

API_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
HF_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")
HF_MODEL = "TheBloke/wizardLM-7B-uncensored-HF"  # –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–∞ —ñ —Ä–æ–±–æ—á–∞ –º–æ–¥–µ–ª—å

bot = Bot(token=API_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def start(message: types.Message):
    await message.answer("–ü—Ä–∏–≤—ñ—Ç! –Ø AI FAQ-–±–æ—Ç üöÇ\n–ó–∞–¥–∞–π —Å–≤–æ—î –ø–∏—Ç–∞–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.")

def get_ai_answer(user_question):
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    data = {"inputs": f"–¢–∏ –ø–æ–º—ñ—á–Ω–∏–∫ –∑—ñ —Å—Ç—Ä–∞—Ö–æ–≤–∏—Ö –ø–∏—Ç–∞–Ω—å. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n–ü–∏—Ç–∞–Ω–Ω—è: {user_question}\n–í—ñ–¥–ø–æ–≤—ñ–¥—å:"}

    try:
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{HF_MODEL}",
            headers=headers,
            json=data,
            timeout=60
        )
        result = response.json()
        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"].strip()
        elif isinstance(result, dict) and "error" in result:
            return f"–ü–æ–º–∏–ª–∫–∞ AI: {result['error']}"
        else:
            return "–í–∏–±–∞—á—Ç–µ, AI –Ω–µ –∑–º—ñ–≥ –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å."
    except Exception as e:
        return f"–í–∏–±–∞—á—Ç–µ, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {e}"

@dp.message()
async def handle_question(message: types.Message):
    user_question = message.text.strip()
    answer = get_ai_answer(user_question)
    await message.answer(answer)

async def main():
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ —ñ —á–µ–∫–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
