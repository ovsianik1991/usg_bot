import os
import asyncio
import requests
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command

API_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
HF_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")
HF_MODEL = "TheBloke/wizardLM-7B-uncensored-HF"  # —Ä–æ–±–æ—á–∞ –º–æ–¥–µ–ª—å –¥–ª—è –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ—É

bot = Bot(token=API_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤—ñ—Ç! –Ø AI FAQ-–±–æ—Ç üöÇ\n–ó–∞–¥–∞–π —Å–≤–æ—î –ø–∏—Ç–∞–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é."
    )

def get_ai_answer(question):
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    payload = {
        "inputs": f"–¢–∏ –ø–æ–º—ñ—á–Ω–∏–∫ –∑—ñ —Å—Ç—Ä–∞—Ö–æ–≤–∏—Ö –ø–∏—Ç–∞–Ω—å. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n–ü–∏—Ç–∞–Ω–Ω—è: {question}\n–í—ñ–¥–ø–æ–≤—ñ–¥—å:"
    }
    url = f"https://api-inference.huggingface.co/models/{HF_MODEL}"

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        data = response.json()
        if isinstance(data, list) and "generated_text" in data[0]:
            return data[0]["generated_text"].strip()
        elif isinstance(data, dict) and "error" in data:
            return f"–ü–æ–º–∏–ª–∫–∞ AI: {data['error']}"
        else:
            return "–í–∏–±–∞—á—Ç–µ, AI –Ω–µ –∑–º—ñ–≥ –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å."
    except requests.exceptions.HTTPError as e:
        return f"HTTP –ø–æ–º–∏–ª–∫–∞: {e}"
    except Exception as e:
        return f"–°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞: {e}"

@dp.message()
async def handle_question(message: types.Message):
    question = message.text.strip()
    answer = get_ai_answer(question)
    await message.answer(answer)

async def main():
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ —ñ —á–µ–∫–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
